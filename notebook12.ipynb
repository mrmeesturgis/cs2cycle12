{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8bba665",
   "metadata": {},
   "source": [
    "<img src=\"https://www.sturgischarterschool.com/wp-content/uploads/2019/06/sturgisheader_logo.png\" alt=\"sturgis\" width=\"250\" align=\"right\"/>\n",
    "\n",
    "## Computer Science 'May I Recommend Part 2' notebook 16\n",
    "### Sturgis Charter Public School \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681696fb",
   "metadata": {},
   "source": [
    "Student: [your name here]\n",
    "\n",
    "Collaborators: [N/A]\n",
    "\n",
    "Notes to the teacher: [N/A]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf0839",
   "metadata": {},
   "source": [
    "### Learning Objectives for notebook \n",
    "\n",
    "Part II\n",
    "\n",
    "* The Dot Product\n",
    "* Mean Square Error\n",
    "* Gradient Descent\n",
    "* Matrix Factorization\n",
    "\n",
    "Helpful links:\n",
    "* [Dot product 1: Built In](https://builtin.com/data-science/dot-product-matrix)\n",
    "* [Dot product 2: Better Explained](https://betterexplained.com/articles/vector-calculus-understanding-the-dot-product/)\n",
    "* \n",
    "\n",
    "In case you're curious:\n",
    "* [Basic Markdown Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "* [LaTex putting math in your Jupyter Notebooks](https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd)\n",
    "* [Generating a table in Markdown](https://www.tablesgenerator.com/markdown_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ae9843",
   "metadata": {},
   "source": [
    "Note: Code for this notebook is largely sourced from other published articles. Credit where it's due: [Denise Chen](https://towardsdatascience.com/recommendation-system-matrix-factorization-d61978660b4b), who has an awesome article on exactly this topic. [George Seif](https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3) discusses Mean Squared Error. \n",
    "\n",
    "### The Dot Product\n",
    "\n",
    "The dot product formula looks like the following. \n",
    "\n",
    "$$ \\vec{a} \\, \\cdot \\, \\vec{b} = {a_1} \\cdot \\, {b_1}  + {a_n} \\cdot \\, {b_n}  $$\n",
    "\n",
    "Let's think about matrices. To me the term has long had a connotation of mysterious, and difficult. Let's try and simplify things. A matrix is just a 2-dimensional array (at least to start). It is a series of one-dimensional arrays--or vectors--and that is pretty easy to understand. In looking at recommender systems it makes sense that we would have a vector. Consider the example below, where `Fn` is a feature number, and `U1` is a user. In this case we are simply saying, we know how much our user likes particular features. Just what are those features? We don't care right now! :D\n",
    "\n",
    "|User |  F1 |  F2 | F3  | F4  |\n",
    "|---|---|---|---|---|\n",
    "| u1  | 1  | 3  |  7 |  0 |\n",
    "\n",
    "Now let's imagine that we had another vector, but for this one we have items. The features between the two are the same, but on one hand we want to know how similar the user is to the item. In essence, which item should we recommend? Well to be honest, we can't do that with just a vector. We could take a guess at how much `u1` will like `i1`. That's going to be result of the dot product. \n",
    "\n",
    "|Item |  F1 |  F2 | F3  | F4  |\n",
    "|---|---|---|---|---|\n",
    "| i1  | 5  | 2  |  8 |  9 |\n",
    "\n",
    "Let's multiply these two vectors. That's going to look like this:\n",
    "\n",
    "$$ u1(F1) \\cdot i1(F1) + u1(F2) \\cdot i1(F2) + u1(F3) \\cdot i1(F3) + u1(F4) \\cdot i1(F4) = Total Similarity $$\n",
    "\n",
    "Now there's a couple things to note. \n",
    "\n",
    "The first is `WHERE DID OUR VECTOR GO?` That's right it's gone, and when you look at the formula it makes sense.\n",
    "\n",
    "$$ \\vec{a} \\, \\cdot \\, \\vec{b} = {a_1} \\cdot \\, {b_1}  + {a_n} \\cdot \\, {b_n}  $$\n",
    "\n",
    "Think of it this way. You may like a videogame for many reasons (features), but your overall liking of the game is a single score.\n",
    "\n",
    "But that's a vector operation. We haven't even gotten to matrixes. What's interesting is that we may have a hundred features, but if we have only 1 user and 1 item, then we will have only 1 number as a result. \n",
    "\n",
    "...What happens if we have 10 users, and 10 features? You can look below for what that would look like. If we multiply those matrices, we will actually end up with a 10 by 10 matrix, even if we only had two features. \n",
    "\n",
    "Think about it, we would want to give a recommendation to each user for each item. And these 100 items will be represented as 10 vectors: 1 vector per user. $$ 10 \\cdot \\, 10 = 100 $$ \n",
    "\n",
    "The beauty is that while it's a bunch of math, we're in computer science. We can just ask the computer to do it for us. Thanks, Numpy and/or Pandas!\n",
    "\n",
    "### Mean Squared Error\n",
    "\n",
    "The Mean Error looks like the following: \n",
    "\n",
    "$$ \\sum_{i=1}^{N}(x_i-y_i)^2 $$\n",
    "\n",
    "And it's purpose is to be able to calculate how far off you were from a perfect guess. Think of it this way: we want to know not simply that our guess is wrong (it's almost guaranteed to be tha) but we want to know how wrong it is. This is basically playing a game of hot and cold. Our first guess is likely to be very cold, and so we want a high loss. Our second guess is going to be informed by our first guess, and so on and so forth. Now, the Mean Squared Error is simply a choice (and a very common data science choice) for how we know how far we off. It's the language we're choosing instead of `hotter` and `colder`. \n",
    "\n",
    "If you want to see some code, then [George Seif](https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3) discusses Mean Squared Error. \n",
    "\n",
    " \n",
    "### Gradient Descent\n",
    "\n",
    "So imagine that we realize that we are very `cold`. Well the next thing to do is try to get warmer, but our response to that `loss` is important. How big of a step do we take?\n",
    "\n",
    "Here it's helpful to visualize our loss. [Robert Kwiatkowski](https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21) has a very mathy article that discusses gradient descent. It's quite good, and waaaayy to much to digest. But let's take a look at some of the images. \n",
    "\n",
    "![Gradient Descent](Gradient_Descent_Example.png)\n",
    "\n",
    "This is a beautiful display of the difference that can happen depending on how big of steps the model takes. Note that those steps are not always the same distance. Why is that? Well, the answer is we are using our awareness of the loss, and we are then calculating how big of a step we need to take. \n",
    "\n",
    "Which learning rate is best? Well that kind of depends. Generally, however, it's a really small number because if your learning rate is too big, you might just constantly be bouncing past the optimal value. \n",
    "\n",
    "What is the optimal value? Well the answer to that is of course, the value that is most like the value we know to be true!\n",
    "\n",
    "### Matrix Factorization\n",
    "\n",
    "Alright, so why would we bother doing gradient descent on values we already know? Because we can extrapolate patterns on values we don't know. The goal here is to find the values that should be there. This is where Matrix Factorization comes in. \n",
    "\n",
    "Alright, let's remind ourselves/look up for the first time. If we know what a matrix is, then what is factorization? Well according to [vocabulary.com](https://www.vocabulary.com/dictionary/factorization) the answer is: \n",
    "> In math, factorization is when you break a number down into smaller numbers that, multiplied together, give you that original number. \n",
    "\n",
    "Ah! That makes so much sense! We have three matrices. The first is the User-Feature matrix, where we know the feature values for every user. The second is the Item-Feature matrix, where we know the feature values for every item. These are the smaller matrices. If we multiply these two matrices using the dot product, then we have our third matrix, which is the user-item matrix. This third matrix is the key, because we can use it to check our values in the two smaller matrices. In fact, we could start with random numbers in matrix one and two, and by using gradient descent we can return those values to what they ought to be. \n",
    "\n",
    "How is this possible? ***`Magic`*** of course!\n",
    "\n",
    "No, rather we are comparing our decomposed tables against our known table, and then improving the values in the decomposed table. One awesome side-effect of this is that we also bring the 0's along for the ride. Honestly it doesn't seem like this should work, but it does!\n",
    "\n",
    "Now, what is the output of our matrix factorization. We've fixed matrix one and two, but how do we transform that back to our new and improved User-Item matrix three. Use the dot product once more, of course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3eb272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's load two csv's\n",
    "import pandas as pd\n",
    "usf = pd.read_csv('User_Features.csv')\n",
    "itf = pd.read_csv('Item_Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "usf = usf.head(10)\n",
    "itf = itf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e87f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "usf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "itf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a67c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "usf = usf.iloc[:,1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be642f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "itf = itf.iloc[:,1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be181c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "usf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c7536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "itf = itf.T\n",
    "itf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a30ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "usf.dot(itf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e7db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy\n",
    "\n",
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    '''\n",
    "    R: rating matrix\n",
    "    P: |U| * K (User features matrix)\n",
    "    Q: |D| * K (Item features matrix)\n",
    "    K: latent features\n",
    "    steps: iterations\n",
    "    alpha: learning rate\n",
    "    beta: regularization parameter'''\n",
    "    Q = Q.T\n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    # calculate error\n",
    "                    eij = R[i][j] - numpy.dot(P[i,:],Q[:,j])\n",
    "\n",
    "                    for k in range(K):\n",
    "                        # calculate gradient with a and beta parameter\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "\n",
    "        eR = numpy.dot(P,Q)\n",
    "\n",
    "        e = 0\n",
    "\n",
    "        for i in range(len(R)):\n",
    "\n",
    "            for j in range(len(R[i])):\n",
    "\n",
    "                if R[i][j] > 0:\n",
    "\n",
    "                    e = e + pow(R[i][j] - numpy.dot(P[i,:],Q[:,j]), 2)\n",
    "\n",
    "                    for k in range(K):\n",
    "\n",
    "                        e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))\n",
    "        # 0.001: local minimum\n",
    "        if e < 0.001:\n",
    "\n",
    "            break\n",
    "\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f925e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = [\n",
    "\n",
    "     [5,3,0,1],\n",
    "\n",
    "     [4,0,0,1],\n",
    "\n",
    "     [1,1,0,5],\n",
    "\n",
    "     [1,0,0,4],\n",
    "\n",
    "     [0,1,5,4],\n",
    "    \n",
    "     [2,1,3,0],\n",
    "\n",
    "    ]\n",
    "\n",
    "R = numpy.array(R)\n",
    "# N: num of User\n",
    "N = len(R)\n",
    "# M: num of Movie\n",
    "M = len(R[0])\n",
    "# Num of Features\n",
    "K = 3\n",
    "\n",
    " \n",
    "P = numpy.random.rand(N,K)\n",
    "Q = numpy.random.rand(M,K)\n",
    "\n",
    " \n",
    "\n",
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "\n",
    "nR = numpy.dot(nP, nQ.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "nR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca29904",
   "metadata": {},
   "source": [
    "### Question 1 (and only one :) \n",
    "\n",
    "Use the above code, and the above example csv files for user and item features, and implement gradient descent. You should end up with an `R` dataframe that has no zeros in it. Remember the `R` dataframe is the combination of the `P`--User Features--and `Q`--Item Features dataframes.\n",
    "\n",
    "A couple notes:\n",
    "* You will probably want to change your dataframe into a numpy array. This is easy to do, just read the documentation. \n",
    "* You probably won't have to change the above function at all. \n",
    "* Except you might want to mess with some of the function parameters, just for fun. What happens when you change alpha and beta--what do they represent here? What happens with more steps? What happens with less?\n",
    "* It's helpful to look at the matrices before they go into the function...and after they come back out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749fa822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd07df7",
   "metadata": {},
   "source": [
    "### Stretch Goal: Use item and user features from the previous notebook\n",
    "\n",
    "This is definitely in the stretch goal category, but it would be awesome to have a recommender system that made a real recommendation, and not simply a mockaroo recommendation. This is NOT a requirement, and the only reward for all your hard work (which would be a lot of hard work) is the satisfaction of having built something awesome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5e2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
